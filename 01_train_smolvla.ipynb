{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "mount_file_id": "1QKKKQV8hk-shxfQmGrVXCxCZKACRJPAr",
      "authorship_tag": "ABX9TyODYnSNpt+llUF+B8JEqtkS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sa74ll/ELM_challenge/blob/main/01_train_smolvla.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SmolVLA Training with Color Augmentation\n",
        "Goal: Train on episodes 0-39, validate on 40-49 with different color augmentations"
      ],
      "metadata": {
        "id": "5RnQQXee7Ajn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install LeRobot**\n",
        "\n",
        "This cell clones the `lerobot` repository from Hugging Face"
      ],
      "metadata": {
        "id": "C-P9DU1vCfLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/huggingface/lerobot.git\n",
        "%cd /content/lerobot\n",
        "!pip install -e .\n"
      ],
      "metadata": {
        "id": "JLmu3BPdbTNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "atGL3U1TbS9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/lerobot && pip install -e \".[smolvla]\""
      ],
      "metadata": {
        "id": "v_kRgRAlCzlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "SmolVLA Training with Color Augmentation Challenge\n",
        "Goal: Train on episodes 0-39, validate on 40-49 with different color augmentations\n",
        "\"\"\"\n",
        "\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import numpy as np\n",
        "from lerobot.datasets.lerobot_dataset import LeRobotDataset, LeRobotDatasetMetadata\n",
        "from lerobot.datasets.transforms import (\n",
        "    ImageTransforms,\n",
        "    ImageTransformsConfig,\n",
        "    ImageTransformConfig,\n",
        ")\n",
        "from lerobot.policies.smolvla.modeling_smolvla import SmolVLAPolicy\n",
        "from lerobot.policies.factory import make_pre_post_processors\n",
        "import wandb\n",
        "\n",
        "#Configuration\n",
        "DATASET_REPO = \"lerobot/svla_so101_pickplace\"\n",
        "OUTPUT_DIR = Path(\"/content/Final_challenge/lerobot_output/smolvla_proper_split_final\")\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "BATCH_SIZE = 24\n",
        "MAX_STEPS = 15000\n",
        "VAL_EVERY = 1000\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbANFSH44Kss",
        "outputId": "77dd4eaf-a85e-4dfa-9aea-a34c27f4cba3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Weights & Biases setup\n",
        "wandb.init(\n",
        "    project=\"Final2\",\n",
        "    name=\"smolvla_split\",\n",
        "    config={\n",
        "        \"dataset\": DATASET_REPO,\n",
        "        \"batch_size\": BATCH_SIZE,\n",
        "        \"max_steps\": MAX_STEPS,\n",
        "        \"train_episodes\": \"0-39\",\n",
        "        \"val_episodes\": \"40-49\",\n",
        "        \"video_backend\": \"pyav\",\n",
        "    },\n",
        ")"
      ],
      "metadata": {
        "id": "Duwqrgox4PBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "SmolVLA uses chunk_size=50 by default for action sequences\n",
        "so we need to match this in our delta_timestamps configuration\n",
        "\"\"\"\n",
        "policy = SmolVLAPolicy.from_pretrained(\"lerobot/smolvla_base\")\n",
        "policy.to(device).train()\n",
        "\n",
        "#Extract action horizon from policy config\n",
        "action_horizon = policy.config.chunk_size\n",
        "print(\"Policy action horizon :\", action_horizon)"
      ],
      "metadata": {
        "id": "ip5k0qMm4Sdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Configure temporal structure to match SmolVLA expectations\n",
        "Actions need timestamps for the full action chunk\n",
        "\"\"\"\n",
        "meta = LeRobotDatasetMetadata(DATASET_REPO)\n",
        "fps = meta.fps\n",
        "print(\"Dataset FPS:\", fps)\n",
        "\n",
        "# actions: 0, 1/fps, 2/fps, ..., (chunk_size-1)/fps\n",
        "action_dts = [i / fps for i in range(action_horizon)]\n",
        "\n",
        "# images & state: one timestamp\n",
        "delta_timestamps = {\n",
        "    \"observation.state\": [0.0],\n",
        "    \"observation.images.up\": [0.0],\n",
        "    \"observation.images.side\": [0.0],\n",
        "    \"action\": action_dts,\n",
        "}\n",
        "print(\"Using delta_timestamps:\", delta_timestamps)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjU8f7GR4W5x",
        "outputId": "52d17bd5-950c-4cb1-f680-ab04a9ea788f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset FPS: 30\n",
            "Using delta_timestamps: {'observation.state': [0.0], 'observation.images.up': [0.0], 'observation.images.side': [0.0], 'action': [0.0, 0.03333333333333333, 0.06666666666666667, 0.1, 0.13333333333333333, 0.16666666666666666, 0.2, 0.23333333333333334, 0.26666666666666666, 0.3, 0.3333333333333333, 0.36666666666666664, 0.4, 0.43333333333333335, 0.4666666666666667, 0.5, 0.5333333333333333, 0.5666666666666667, 0.6, 0.6333333333333333, 0.6666666666666666, 0.7, 0.7333333333333333, 0.7666666666666667, 0.8, 0.8333333333333334, 0.8666666666666667, 0.9, 0.9333333333333333, 0.9666666666666667, 1.0, 1.0333333333333334, 1.0666666666666667, 1.1, 1.1333333333333333, 1.1666666666666667, 1.2, 1.2333333333333334, 1.2666666666666666, 1.3, 1.3333333333333333, 1.3666666666666667, 1.4, 1.4333333333333333, 1.4666666666666666, 1.5, 1.5333333333333334, 1.5666666666666667, 1.6, 1.6333333333333333]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Load base dataset to determine train/val split\n",
        "Using pyav backend due to torchcodec issues in Colab (common issue in LeRobot GitHub)\n",
        "\"\"\"\n",
        "print(\"Loading base dataset to read episode_index\")\n",
        "base_ds = LeRobotDataset(\n",
        "    DATASET_REPO,\n",
        "    video_backend=\"pyav\",  # to avoid torchcodec issues\n",
        ")\n",
        "sample = base_ds[0]\n",
        "print(\"Available keys:\", list(sample.keys()))\n",
        "\n",
        "# build 40/10 split based on episode_index\n",
        "episode_idx = np.array(base_ds.hf_dataset[\"episode_index\"])\n",
        "train_indices = [i for i, ep in enumerate(episode_idx) if ep < 40]\n",
        "val_indices = [i for i, ep in enumerate(episode_idx) if ep >= 40]\n",
        "print(f\"Found {len(train_indices)} train samples and {len(val_indices)} val samples\")\n"
      ],
      "metadata": {
        "id": "OU8DKTaI4e-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#IMAGE AUGMENTATIONS\n",
        "\n",
        "train_tf_cfg = ImageTransformsConfig(\n",
        "    enable=True,\n",
        "    max_num_transforms=2,\n",
        "    random_order=True,\n",
        "    tfs={\n",
        "        \"brightness\": ImageTransformConfig(\n",
        "            weight=1.0, type=\"ColorJitter\", kwargs={\"brightness\": (0.8, 1.2)}\n",
        "        ),\n",
        "        \"contrast\": ImageTransformConfig(\n",
        "            weight=1.0, type=\"ColorJitter\", kwargs={\"contrast\": (0.8, 1.2)}\n",
        "        ),\n",
        "        \"saturation\": ImageTransformConfig(\n",
        "            weight=1.0, type=\"ColorJitter\", kwargs={\"saturation\": (0.5, 1.5)}\n",
        "        ),\n",
        "        \"hue\": ImageTransformConfig(\n",
        "            weight=1.0, type=\"ColorJitter\", kwargs={\"hue\": (-0.05, 0.05)}\n",
        "        ),\n",
        "    },\n",
        ")\n",
        "\n",
        "# val slightly darker than train\n",
        "val_tf_cfg = ImageTransformsConfig(\n",
        "    enable=True,\n",
        "    max_num_transforms=2,\n",
        "    random_order=True,\n",
        "    tfs={\n",
        "        \"brightness\": ImageTransformConfig(\n",
        "            weight=1.0, type=\"ColorJitter\", kwargs={\"brightness\": (0.7, 1.0)}\n",
        "        ),\n",
        "        \"contrast\": ImageTransformConfig(\n",
        "            weight=1.0, type=\"ColorJitter\", kwargs={\"contrast\": (1.0, 1.3)}\n",
        "        ),\n",
        "        \"saturation\": ImageTransformConfig(\n",
        "            weight=1.0, type=\"ColorJitter\", kwargs={\"saturation\": (0.5, 1.2)}\n",
        "        ),\n",
        "        \"hue\": ImageTransformConfig(\n",
        "            weight=1.0, type=\"ColorJitter\", kwargs={\"hue\": (-0.08, 0.06)}\n",
        "        ),\n",
        "    },\n",
        ")\n",
        "\n",
        "train_tf = ImageTransforms(train_tf_cfg)\n",
        "val_tf = ImageTransforms(val_tf_cfg)\n"
      ],
      "metadata": {
        "id": "3c8c1pQd4lkG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Create separate datasets train/val with different augmentations\n",
        "Then apply episode-based splits using Subset\n",
        "\"\"\"\n",
        "\n",
        "train_full = LeRobotDataset(\n",
        "    DATASET_REPO,\n",
        "    delta_timestamps=delta_timestamps,\n",
        "    image_transforms=train_tf,\n",
        "    video_backend=\"pyav\",\n",
        ")\n",
        "\n",
        "val_full = LeRobotDataset(\n",
        "    DATASET_REPO,\n",
        "    delta_timestamps=delta_timestamps,\n",
        "    image_transforms=val_tf,\n",
        "    video_backend=\"pyav\",\n",
        ")\n",
        "\n",
        "# final split\n",
        "train_ds = Subset(train_full, train_indices)\n",
        "val_ds = Subset(val_full, val_indices)\n",
        "\n",
        "print(f\"Train: {len(train_ds)}, Val: {len(val_ds)}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "GfdjieuQ4sYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Create efficient data loading with proper settings\"\"\"\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    pin_memory=True,\n",
        "    num_workers=2,  # Reduced for Colab stability\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    pin_memory=True,\n",
        "    num_workers=2,\n",
        ")"
      ],
      "metadata": {
        "id": "Vi70S9wh4x3G"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Setup data preprocessing and optimisation\"\"\"\n",
        "\n",
        "#create preprocessors using dataset stat\n",
        "preprocessor, postprocessor = make_pre_post_processors(\n",
        "    policy.config,\n",
        "    dataset_stats=meta.stats,\n",
        ")\n",
        "\n",
        "optimizer = policy.config.get_optimizer_preset().build(policy.parameters())"
      ],
      "metadata": {
        "id": "WNzTkG_M43eP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Helper Functions\n",
        "\n",
        "def fix_keys(batch: dict) -> dict:\n",
        "    \"\"\"\n",
        "    Fix camera naming convention\n",
        "    SmolVLA expects camera1/camera2, dataset provides up/side\n",
        "    \"\"\"\n",
        "    if \"observation.images.up\" in batch:\n",
        "        batch[\"observation.images.camera1\"] = batch.pop(\"observation.images.up\")\n",
        "    if \"observation.images.side\" in batch:\n",
        "        batch[\"observation.images.camera2\"] = batch.pop(\"observation.images.side\")\n",
        "\n",
        "    return batch\n"
      ],
      "metadata": {
        "id": "dhbSfIuH465D"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main training loop - step-based to resume whenever Colab runtime crashes\n",
        "\n",
        "best_val = float(\"inf\")\n",
        "step = 0\n",
        "CKPT_EVERY = 1000\n",
        "LOG_EVERY = 100\n",
        "print(f\"Starting training for {MAX_STEPS} steps...\")\n",
        "\n",
        "while step < MAX_STEPS:\n",
        "    for raw_batch in train_loader:\n",
        "        # 1 normalize\n",
        "        raw_batch = fix_keys(raw_batch)\n",
        "        #raw_batch = ensure_task(raw_batch)\n",
        "\n",
        "        # 2 run preprocessor\n",
        "        batch = preprocessor(raw_batch)\n",
        "\n",
        "        # 3 move tensors to GPU\n",
        "        for k, v in list(batch.items()):\n",
        "            if torch.is_tensor(v):\n",
        "                batch[k] = v.to(device, non_blocking=True)\n",
        "\n",
        "        # 4) forward\n",
        "        out = policy.forward(batch)\n",
        "        if isinstance(out, tuple):\n",
        "            loss = out[0]\n",
        "        else:\n",
        "            loss = out[\"loss\"]\n",
        "\n",
        "        # 5 backward\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 6 logging\n",
        "        if step % LOG_EVERY == 0:\n",
        "            print(f\"[step {step}] train loss = {loss.item():.4f}\")\n",
        "            wandb.log({\"train/loss\": loss.item(), \"step\": step})\n",
        "\n",
        "        # 7 validation\n",
        "        if step > 0 and step % VAL_EVERY == 0:\n",
        "            policy.eval()\n",
        "            val_losses = []\n",
        "            with torch.no_grad():\n",
        "                for i, vraw in enumerate(val_loader):\n",
        "                    if i >= 50:  # keep val short\n",
        "                        break\n",
        "\n",
        "                    vraw = fix_keys(vraw)\n",
        "                    vbatch = preprocessor(vraw)\n",
        "\n",
        "                    for k, v in list(vbatch.items()):\n",
        "                        if torch.is_tensor(v):\n",
        "                            vbatch[k] = v.to(device, non_blocking=True)\n",
        "\n",
        "                    vout = policy.forward(vbatch)\n",
        "                    if isinstance(vout, tuple):\n",
        "                        vloss = vout[0].item()\n",
        "                    else:\n",
        "                        vloss = vout[\"loss\"].item()\n",
        "\n",
        "                    val_losses.append(vloss)\n",
        "\n",
        "            val_loss = sum(val_losses) / len(val_losses)\n",
        "            print(f\"[step {step}] val loss = {val_loss:.4f}\")\n",
        "            wandb.log({\"val/loss\": val_loss, \"step\": step})\n",
        "\n",
        "\n",
        "            # sometimes earlier checkpoints generalise better, so we keep the best val\n",
        "            if val_loss < best_val:\n",
        "                best_val = val_loss\n",
        "                best_dir = OUTPUT_DIR / \"best_model\"\n",
        "                best_dir.mkdir(exist_ok=True)\n",
        "                policy.save_pretrained(best_dir)\n",
        "                preprocessor.save_pretrained(best_dir)\n",
        "                postprocessor.save_pretrained(best_dir)\n",
        "                print(\"new best model saved\")\n",
        "\n",
        "            policy.train()\n",
        "\n",
        "        # 8 checkpoint every 1k step\n",
        "        if step > 0 and step % CKPT_EVERY == 0:\n",
        "            ckpt_dir = OUTPUT_DIR / f\"checkpoint-{step}\"\n",
        "            ckpt_dir.mkdir(exist_ok=True)\n",
        "            policy.save_pretrained(ckpt_dir)\n",
        "            preprocessor.save_pretrained(ckpt_dir)\n",
        "            postprocessor.save_pretrained(ckpt_dir)\n",
        "            print(f\"Checkpoint saved at {ckpt_dir}\")\n",
        "\n",
        "        step += 1\n",
        "        if step >= MAX_STEPS:\n",
        "            break\n",
        "\n",
        "#9 FINAL SAVE\n",
        "policy.save_pretrained(OUTPUT_DIR)\n",
        "preprocessor.save_pretrained(OUTPUT_DIR)\n",
        "postprocessor.save_pretrained(OUTPUT_DIR)\n",
        "print(f\"Done. Best val loss = {best_val:.4f}\")"
      ],
      "metadata": {
        "id": "ef_9qn-k5E38"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}