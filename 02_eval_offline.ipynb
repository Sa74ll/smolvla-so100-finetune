{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "mount_file_id": "16o0y1wUEfJNNVOEsNz0AOBj_GAUvyGBQ",
      "authorship_tag": "ABX9TyOa0mn1p5nomOp11Xj3of1g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sa74ll/ELM_challenge/blob/main/02_eval_offline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGJ9JIk8d5-2",
        "outputId": "577827a1-1c2a-4491-ae78-c2f3ac15d256"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'lerobot'...\n",
            "remote: Enumerating objects: 41105, done.\u001b[K\n",
            "remote: Counting objects: 100% (122/122), done.\u001b[K\n",
            "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
            "remote: Total 41105 (delta 95), reused 59 (delta 59), pack-reused 40983 (from 3)\u001b[K\n",
            "Receiving objects: 100% (41105/41105), 201.76 MiB | 16.56 MiB/s, done.\n",
            "Resolving deltas: 100% (26734/26734), done.\n",
            "Filtering content: 100% (45/45), 69.03 MiB | 22.29 MiB/s, done.\n",
            "/content/lerobot\n",
            "Obtaining file:///content/lerobot\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: datasets<4.2.0,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from lerobot==0.4.1) (4.0.0)\n",
            "Requirement already satisfied: diffusers<0.36.0,>=0.27.2 in /usr/local/lib/python3.12/dist-packages (from lerobot==0.4.1) (0.35.2)\n",
            "Collecting huggingface-hub<0.36.0,>=0.34.2 (from huggingface-hub[cli,hf-transfer]<0.36.0,>=0.34.2->lerobot==0.4.1)\n",
            "  Downloading huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: accelerate<2.0.0,>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from lerobot==0.4.1) (1.11.0)\n",
            "Requirement already satisfied: setuptools<81.0.0,>=71.0.0 in /usr/local/lib/python3.12/dist-packages (from lerobot==0.4.1) (75.2.0)\n",
            "Requirement already satisfied: cmake<4.2.0,>=3.29.0.1 in /usr/local/lib/python3.12/dist-packages (from lerobot==0.4.1) (3.31.6)\n",
            "Requirement already satisfied: einops<0.9.0,>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from lerobot==0.4.1) (0.8.1)\n",
            "Requirement already satisfied: opencv-python-headless<4.13.0,>=4.9.0 in /usr/local/lib/python3.12/dist-packages (from lerobot==0.4.1) (4.12.0.88)\n",
            "Collecting av<16.0.0,>=15.0.0 (from lerobot==0.4.1)\n",
            "  Downloading av-15.1.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting jsonlines<5.0.0,>=4.0.0 (from lerobot==0.4.1)\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: packaging<26.0,>=24.2 in /usr/local/lib/python3.12/dist-packages (from lerobot==0.4.1) (25.0)\n",
            "Collecting pynput<1.9.0,>=1.7.7 (from lerobot==0.4.1)\n",
            "  Downloading pynput-1.8.1-py2.py3-none-any.whl.metadata (32 kB)\n",
            "Collecting pyserial<4.0,>=3.5 (from lerobot==0.4.1)\n",
            "  Downloading pyserial-3.5-py2.py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting wandb<0.22.0,>=0.20.0 (from lerobot==0.4.1)\n",
            "  Downloading wandb-0.21.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting torch<2.8.0,>=2.2.1 (from lerobot==0.4.1)\n",
            "  Downloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Collecting torchcodec<0.6.0,>=0.2.1 (from lerobot==0.4.1)\n",
            "  Downloading torchcodec-0.5-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
            "Collecting torchvision<0.23.0,>=0.21.0 (from lerobot==0.4.1)\n",
            "  Downloading torchvision-0.22.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting draccus==0.10.0 (from lerobot==0.4.1)\n",
            "  Downloading draccus-0.10.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: gymnasium<2.0.0,>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from lerobot==0.4.1) (1.2.1)\n",
            "Collecting rerun-sdk<0.27.0,>=0.24.0 (from lerobot==0.4.1)\n",
            "  Downloading rerun_sdk-0.26.2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting deepdiff<9.0.0,>=7.0.1 (from lerobot==0.4.1)\n",
            "  Downloading deepdiff-8.6.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: imageio<3.0.0,>=2.34.0 in /usr/local/lib/python3.12/dist-packages (from imageio[ffmpeg]<3.0.0,>=2.34.0->lerobot==0.4.1) (2.37.0)\n",
            "Requirement already satisfied: termcolor<4.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from lerobot==0.4.1) (3.2.0)\n",
            "Collecting mergedeep~=1.3 (from draccus==0.10.0->lerobot==0.4.1)\n",
            "  Downloading mergedeep-1.3.4-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: pyyaml~=6.0 in /usr/local/lib/python3.12/dist-packages (from draccus==0.10.0->lerobot==0.4.1) (6.0.3)\n",
            "Collecting pyyaml-include~=1.4 (from draccus==0.10.0->lerobot==0.4.1)\n",
            "  Downloading pyyaml_include-1.4.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: toml~=0.10 in /usr/local/lib/python3.12/dist-packages (from draccus==0.10.0->lerobot==0.4.1) (0.10.2)\n",
            "Collecting typing-inspect~=0.9.0 (from draccus==0.10.0->lerobot==0.4.1)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate<2.0.0,>=1.10.0->lerobot==0.4.1) (2.0.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate<2.0.0,>=1.10.0->lerobot==0.4.1) (5.9.5)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate<2.0.0,>=1.10.0->lerobot==0.4.1) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets<4.2.0,>=4.0.0->lerobot==0.4.1) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets<4.2.0,>=4.0.0->lerobot==0.4.1) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets<4.2.0,>=4.0.0->lerobot==0.4.1) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets<4.2.0,>=4.0.0->lerobot==0.4.1) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets<4.2.0,>=4.0.0->lerobot==0.4.1) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets<4.2.0,>=4.0.0->lerobot==0.4.1) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets<4.2.0,>=4.0.0->lerobot==0.4.1) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets<4.2.0,>=4.0.0->lerobot==0.4.1) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.2.0,>=4.0.0->lerobot==0.4.1) (2025.3.0)\n",
            "Collecting orderly-set<6,>=5.4.1 (from deepdiff<9.0.0,>=7.0.1->lerobot==0.4.1)\n",
            "  Downloading orderly_set-5.5.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers<0.36.0,>=0.27.2->lerobot==0.4.1) (8.7.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from diffusers<0.36.0,>=0.27.2->lerobot==0.4.1) (2024.11.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from diffusers<0.36.0,>=0.27.2->lerobot==0.4.1) (11.3.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium<2.0.0,>=1.1.1->lerobot==0.4.1) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium<2.0.0,>=1.1.1->lerobot==0.4.1) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium<2.0.0,>=1.1.1->lerobot==0.4.1) (0.0.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<0.36.0,>=0.34.2->huggingface-hub[cli,hf-transfer]<0.36.0,>=0.34.2->lerobot==0.4.1) (1.2.0)\n",
            "Collecting InquirerPy==0.3.4 (from huggingface-hub[cli,hf-transfer]<0.36.0,>=0.34.2->lerobot==0.4.1)\n",
            "  Downloading InquirerPy-0.3.4-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: hf-transfer>=0.1.4 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub[cli,hf-transfer]<0.36.0,>=0.34.2->lerobot==0.4.1) (0.1.9)\n",
            "Collecting pfzy<0.4.0,>=0.3.1 (from InquirerPy==0.3.4->huggingface-hub[cli,hf-transfer]<0.36.0,>=0.34.2->lerobot==0.4.1)\n",
            "  Downloading pfzy-0.3.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from InquirerPy==0.3.4->huggingface-hub[cli,hf-transfer]<0.36.0,>=0.34.2->lerobot==0.4.1) (3.0.52)\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.12/dist-packages (from imageio[ffmpeg]<3.0.0,>=2.34.0->lerobot==0.4.1) (0.6.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonlines<5.0.0,>=4.0.0->lerobot==0.4.1) (25.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from pynput<1.9.0,>=1.7.7->lerobot==0.4.1) (1.17.0)\n",
            "Collecting evdev>=1.3 (from pynput<1.9.0,>=1.7.7->lerobot==0.4.1)\n",
            "  Downloading evdev-1.9.2.tar.gz (33 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-xlib>=0.17 (from pynput<1.9.0,>=1.7.7->lerobot==0.4.1)\n",
            "  Downloading python_xlib-0.33-py2.py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot==0.4.1) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot==0.4.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot==0.4.1) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot==0.4.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot==0.4.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot==0.4.1) (12.6.80)\n",
            "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch<2.8.0,>=2.2.1->lerobot==0.4.1)\n",
            "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot==0.4.1) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot==0.4.1) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot==0.4.1) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot==0.4.1) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot==0.4.1) (12.5.4.2)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch<2.8.0,>=2.2.1->lerobot==0.4.1)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.26.2 (from torch<2.8.0,>=2.2.1->lerobot==0.4.1)\n",
            "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot==0.4.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot==0.4.1) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<2.8.0,>=2.2.1->lerobot==0.4.1) (1.11.1.6)\n",
            "Collecting triton==3.3.1 (from torch<2.8.0,>=2.2.1->lerobot==0.4.1)\n",
            "  Downloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb<0.22.0,>=0.20.0->lerobot==0.4.1) (8.3.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb<0.22.0,>=0.20.0->lerobot==0.4.1) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb<0.22.0,>=0.20.0->lerobot==0.4.1) (4.5.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb<0.22.0,>=0.20.0->lerobot==0.4.1) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb<0.22.0,>=0.20.0->lerobot==0.4.1) (2.11.10)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb<0.22.0,>=0.20.0->lerobot==0.4.1) (2.42.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.2.0,>=4.0.0->lerobot==0.4.1) (3.13.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb<0.22.0,>=0.20.0->lerobot==0.4.1) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb<0.22.0,>=0.20.0->lerobot==0.4.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb<0.22.0,>=0.20.0->lerobot==0.4.1) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb<0.22.0,>=0.20.0->lerobot==0.4.1) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<4.2.0,>=4.0.0->lerobot==0.4.1) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<4.2.0,>=4.0.0->lerobot==0.4.1) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<4.2.0,>=4.0.0->lerobot==0.4.1) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<4.2.0,>=4.0.0->lerobot==0.4.1) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<2.8.0,>=2.2.1->lerobot==0.4.1) (1.3.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect~=0.9.0->draccus==0.10.0->lerobot==0.4.1)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers<0.36.0,>=0.27.2->lerobot==0.4.1) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<2.8.0,>=2.2.1->lerobot==0.4.1) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<4.2.0,>=4.0.0->lerobot==0.4.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<4.2.0,>=4.0.0->lerobot==0.4.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<4.2.0,>=4.0.0->lerobot==0.4.1) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.2.0,>=4.0.0->lerobot==0.4.1) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.2.0,>=4.0.0->lerobot==0.4.1) (1.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.2.0,>=4.0.0->lerobot==0.4.1) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.2.0,>=4.0.0->lerobot==0.4.1) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.2.0,>=4.0.0->lerobot==0.4.1) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.2.0,>=4.0.0->lerobot==0.4.1) (1.22.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb<0.22.0,>=0.20.0->lerobot==0.4.1) (5.0.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit<4.0.0,>=3.0.1->InquirerPy==0.3.4->huggingface-hub[cli,hf-transfer]<0.36.0,>=0.34.2->lerobot==0.4.1) (0.2.14)\n",
            "Downloading draccus-0.10.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.8/71.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading av-15.1.0-cp312-cp312-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deepdiff-8.6.1-py3-none-any.whl (91 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.4/91.4 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading InquirerPy-0.3.4-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading pynput-1.8.1-py2.py3-none-any.whl (91 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.7/91.7 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyserial-3.5-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rerun_sdk-0.26.2-cp39-abi3-manylinux_2_28_x86_64.whl (98.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.8/98.8 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl (821.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.0/821.0 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchcodec-0.5-cp312-cp312-manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.22.1-cp312-cp312-manylinux_2_28_x86_64.whl (7.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wandb-0.21.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.6/19.6 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mergedeep-1.3.4-py3-none-any.whl (6.4 kB)\n",
            "Downloading orderly_set-5.5.0-py3-none-any.whl (13 kB)\n",
            "Downloading python_xlib-0.33-py2.py3-none-any.whl (182 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.2/182.2 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyyaml_include-1.4.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading pfzy-0.3.4-py3-none-any.whl (8.5 kB)\n",
            "Building wheels for collected packages: lerobot, evdev\n",
            "  Building editable for lerobot (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lerobot: filename=lerobot-0.4.1-0.editable-py3-none-any.whl size=15638 sha256=851760922cbd09ac774c321f15733a29ffb9ee5dba23c63e2e883c7e9b9971ad\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-oxsy9mso/wheels/09/b4/fe/75732b1d640db96ba1f856f2b7328b232a03b696a39cb59686\n",
            "  Building wheel for evdev (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for evdev: filename=evdev-1.9.2-cp312-cp312-linux_x86_64.whl size=113492 sha256=2f2e413b6adf3d8652ea86e335a84ee9cb7a26629aa3a4d37b11bb8f6315689f\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/f7/62/6b6f5201f6536a3a9e38c94726e03a3b2bded0aaf7782b12d7\n",
            "Successfully built lerobot evdev\n",
            "Installing collected packages: pyserial, nvidia-cusparselt-cu12, triton, torchcodec, rerun-sdk, pyyaml-include, python-xlib, pfzy, orderly-set, nvidia-nccl-cu12, nvidia-cudnn-cu12, mypy-extensions, mergedeep, jsonlines, evdev, av, typing-inspect, pynput, InquirerPy, huggingface-hub, deepdiff, wandb, torch, draccus, torchvision, lerobot\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.7.1\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.7.1:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.7.1\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.4.0\n",
            "    Uninstalling triton-3.4.0:\n",
            "      Successfully uninstalled triton-3.4.0\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.36.0\n",
            "    Uninstalling huggingface-hub-0.36.0:\n",
            "      Successfully uninstalled huggingface-hub-0.36.0\n",
            "  Attempting uninstall: wandb\n",
            "    Found existing installation: wandb 0.22.2\n",
            "    Uninstalling wandb-0.22.2:\n",
            "      Successfully uninstalled wandb-0.22.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.8.0+cu126\n",
            "    Uninstalling torch-2.8.0+cu126:\n",
            "      Successfully uninstalled torch-2.8.0+cu126\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.23.0+cu126\n",
            "    Uninstalling torchvision-0.23.0+cu126:\n",
            "      Successfully uninstalled torchvision-0.23.0+cu126\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.8.0+cu126 requires torch==2.8.0, but you have torch 2.7.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed InquirerPy-0.3.4 av-15.1.0 deepdiff-8.6.1 draccus-0.10.0 evdev-1.9.2 huggingface-hub-0.35.3 jsonlines-4.0.0 lerobot-0.4.1 mergedeep-1.3.4 mypy-extensions-1.1.0 nvidia-cudnn-cu12-9.5.1.17 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 orderly-set-5.5.0 pfzy-0.3.4 pynput-1.8.1 pyserial-3.5 python-xlib-0.33 pyyaml-include-1.4.1 rerun-sdk-0.26.2 torch-2.7.1 torchcodec-0.5 torchvision-0.22.1 triton-3.3.1 typing-inspect-0.9.0 wandb-0.21.4\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/huggingface/lerobot.git\n",
        "%cd /content/lerobot\n",
        "!pip install -e .\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-emuQWZpoC8",
        "outputId": "1892e9b4-266c-4ed8-b8d1-7ab6dbd5ceed"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m⚠️  Warning: 'huggingface-cli login' is deprecated. Use 'hf auth login' instead.\u001b[0m\n",
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: write).\n",
            "The token `SAWR` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `SAWR`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/lerobot\n",
        "!pip install -e \".[smolvla]\""
      ],
      "metadata": {
        "id": "27DbExP-p-wU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import numpy as np\n",
        "\n",
        "from lerobot.datasets.lerobot_dataset import LeRobotDataset, LeRobotDatasetMetadata\n",
        "from lerobot.policies.smolvla.modeling_smolvla import SmolVLAPolicy\n",
        "from lerobot.policies.factory import make_pre_post_processors\n",
        "\n",
        "# ======================================================\n",
        "# CONFIG\n",
        "# ======================================================\n",
        "DATASET_REPO = \"lerobot/svla_so101_pickplace\"\n",
        "BATCH_SIZE = 24\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "BQsm1mD6fIuf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load policy"
      ],
      "metadata": {
        "id": "DzedoBNawDVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load policy + dataset stats\n",
        "\n",
        "policy = SmolVLAPolicy.from_pretrained(\"Sa74ll/smolvla_so101_color_aug_best_model1\")\n",
        "policy.to(DEVICE).eval()\n",
        "\n",
        "meta = LeRobotDatasetMetadata(DATASET_REPO)\n",
        "preprocessor, _ = make_pre_post_processors(policy.config, dataset_stats=meta.stats)\n",
        "\n",
        "fps = meta.fps\n",
        "chunk_size = policy.config.chunk_size\n",
        "print(\"chunk_size:\", chunk_size)\n",
        "print(\"fps:\", fps)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZMT-H_FfI8U",
        "outputId": "d0b57555-8839-49eb-ac2d-1f5c4e371fc4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading  HuggingFaceTB/SmolVLM2-500M-Video-Instruct weights ...\n",
            "Reducing the number of VLM layers to 16 ...\n",
            "chunk_size: 50\n",
            "fps: 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "action_stats = meta.stats[\"action\"]\n",
        "action_min = torch.tensor(action_stats[\"min\"])\n",
        "action_max = torch.tensor(action_stats[\"max\"])\n",
        "action_mean = torch.tensor(action_stats[\"mean\"])\n",
        "action_std  = torch.tensor(action_stats[\"std\"])\n"
      ],
      "metadata": {
        "id": "i2G5dRPtfJXo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "delta_timestamps = {              # build timestamps to match model\n",
        "    \"observation.state\": [0.0],\n",
        "    \"observation.images.up\": [0.0],\n",
        "    \"observation.images.side\": [0.0],\n",
        "    \"action\": [i / fps for i in range(chunk_size)], #SmolVLA predicts 50 actions (chunk_size), 50 action timestamps from the dataset to match model shape by dividing each action into frame per second (FPS)\n",
        "}"
      ],
      "metadata": {
        "id": "tnYro--0fJlu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build val split (episodes >= 40)\n",
        "base_ds = LeRobotDataset(DATASET_REPO, video_backend=\"pyav\") #load dateset first without delta_timestamps to get the episode indices\n",
        "episode_idx = np.array(base_ds.hf_dataset[\"episode_index\"])\n",
        "val_indices = [i for i, ep in enumerate(episode_idx) if ep >= 40]\n",
        "\n",
        "val_full = LeRobotDataset(\n",
        "    DATASET_REPO,\n",
        "    delta_timestamps=delta_timestamps,\n",
        "    video_backend=\"pyav\",\n",
        ")\n",
        "val_ds = Subset(val_full, val_indices)\n",
        "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
        "print(f\"val samples: {len(val_ds)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwAYvDu6f6KH",
        "outputId": "fe39ae4c-f6aa-42a9-a45b-0635b729c260"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val samples: 2759\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# helpers\n",
        "def fix_keys(batch):\n",
        "    \"\"\" remap camers name \"\"\"\n",
        "    if \"observation.images.up\" in batch:\n",
        "        batch[\"observation.images.camera1\"] = batch.pop(\"observation.images.up\")\n",
        "    if \"observation.images.side\" in batch:\n",
        "        batch[\"observation.images.camera2\"] = batch.pop(\"observation.images.side\")\n",
        "    return batch\n",
        "\n",
        "def unnormalize_pred(pred_norm: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"Model outputs normalized actions (because training loss was on normalized), so map back to dataset space using mean/std from meta.stats\"\"\"\n",
        "    return pred_norm * action_std + action_mean\n",
        "\n"
      ],
      "metadata": {
        "id": "QM_6QsXGf_ve"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# eval\n",
        "all_preds_raw = []\n",
        "all_gts_raw = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, raw in enumerate(val_loader):\n",
        "        \"\"\" ground truth in RAW space (dataset space)\"\"\"\n",
        "        gt_raw = raw[\"action\"][:, 0, :].clone()     # instead of getting all the 50 action (B,T,6), we just get the first action (B,6)\n",
        "\n",
        "        raw = fix_keys(raw)\n",
        "        batch = preprocessor(raw)\n",
        "\n",
        "        for k, v in list(batch.items()):\n",
        "            if torch.is_tensor(v):\n",
        "                batch[k] = v.to(DEVICE)\n",
        "\n",
        "        # model inference to normalised action sequence\n",
        "        pred_seq = policy.predict_action_chunk(batch)    # (B, 50, 6)\n",
        "        pred_step0 = pred_seq[:, 0, :].cpu()             # (B,6) normalized\n",
        "\n",
        "        # bring prediction back to RAW space\n",
        "        pred_raw = unnormalize_pred(pred_step0)          # (B,6)\n",
        "        # append the preds and gts to lists\n",
        "        all_preds_raw.append(pred_raw)\n",
        "        all_gts_raw.append(gt_raw)\n",
        "\n",
        "\n",
        "all_preds_raw = torch.cat(all_preds_raw, dim=0)\n",
        "all_gts_raw   = torch.cat(all_gts_raw, dim=0)\n",
        "\n",
        "print(\"Collected preds:\", all_preds_raw.shape, \"Ground truths:\", all_gts_raw.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pe5kSV1_gBH0",
        "outputId": "769da3e3-bb00-4bb8-a2c0-fe795ae94110"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collected preds: torch.Size([2759, 6]) Ground truths: torch.Size([2759, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics: per-joint 5% of its own range\n",
        "\n",
        "joint_ranges = action_max - action_min\n",
        "tol = joint_ranges * 0.05     # 5% per joint\n",
        "\n",
        "abs_err = torch.abs(all_preds_raw - all_gts_raw)   # (N,6)\n",
        "within_5pr = abs_err <= tol                       # (True/False split)\n",
        "\n",
        "per_joint_success = within_5pr.float().mean(dim=0) * 100.0\n",
        "overall_mean = per_joint_success.mean().item()\n",
        "\n",
        "print(\"\\n========== EVAL (per-joint 5%) ==========\")\n",
        "for j, s in enumerate(per_joint_success):\n",
        "    print(f\"joint {j}: {s:.2f}%\")\n",
        "\n",
        "print(f\"\\nAverage per-joint success (5%): {overall_mean:.2f}%\")\n",
        "print(\"=========================================\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCG_B8x3gIcT",
        "outputId": "cf8d6f21-bd39-48b7-b0cb-f54f2c012f7a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========== EVAL (per-joint 5%) ==========\n",
            "joint 0: 45.81%\n",
            "joint 1: 47.88%\n",
            "joint 2: 70.06%\n",
            "joint 3: 77.46%\n",
            "joint 4: 60.86%\n",
            "joint 5: 63.43%\n",
            "\n",
            "Average per-joint success (5%): 60.92%\n",
            "=========================================\n",
            "\n"
          ]
        }
      ]
    }
  ]
}